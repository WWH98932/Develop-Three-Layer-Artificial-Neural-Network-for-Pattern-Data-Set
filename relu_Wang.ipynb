{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2 = -0.19474271702955998\n",
      "W2 =  [[ 0.46481367  0.59191156  1.00000419  1.00000419]]\n",
      "b1 = -0.34422516710405987\n",
      "W1 =  [[ 0.62759178 -0.23824469]\n",
      " [-0.15219613  0.09509001]\n",
      " [-0.00290131 -0.01961629]\n",
      " [-0.00290131 -0.01961629]]\n",
      "Cost sample = [1.5381254867704481, 0.69502701730107086, 0.68540314917230827, 0.68413490885128136, 0.68352961474218266, 0.68311745605977492, 0.68283776757242853, 0.6826450261226934, 0.68244087021901245, 0.68224598858375385]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define activation functions and its devirative\n",
    "# Identity\n",
    "def identity(yhat):\n",
    "    return yhat\n",
    "# Sigmoid\n",
    "def activation(yhat):\n",
    "    return 1 / (1 + np.exp(-yhat))\n",
    "# ReLU\n",
    "def relu(yhat):\n",
    "    return abs(yhat) * (yhat >= 0)\n",
    "#    return 0 * (yhat < 0)\n",
    "def d_relu(yhat):\n",
    "    return 1 * (yhat >= 0)\n",
    "#    return 0 * (x < 0)\n",
    "\n",
    "# Compute cost function\n",
    "h = 1000\n",
    "alpha = 0.05\n",
    "J = np.zeros([1, h])\n",
    "cost_sample = []\n",
    "cost = []\n",
    "\n",
    "data = np.loadtxt(\"pattern_rand.csv\", delimiter=\",\", skiprows=1)\n",
    "X_train = data[0:320, 0:2].T\n",
    "X_test = data[320:, 0:2].T\n",
    "Y_train = data[0:320, 2:].T\n",
    "Y_test = data[320:, 2:].T\n",
    "\n",
    "# Train set\n",
    "X0 = X_train\n",
    "Y = Y_train\n",
    "# Initialization\n",
    "n = 2\n",
    "m = X0.shape[1]\n",
    "G0 = np.zeros([n, m])\n",
    "G1 = np.zeros([4, m])\n",
    "G2 = np.zeros([1, m])\n",
    "dGdW1 = np.zeros([1, m])\n",
    "dJdW1 = np.zeros([1, n])\n",
    "dJdb1 = 0\n",
    "dGdW2 = np.zeros([1, m])\n",
    "dJdW2 = np.zeros([1, n])\n",
    "dJdb2 = 0\n",
    "# Model Parameters\n",
    "b0 = 0\n",
    "b1 = 0\n",
    "b2 = 1\n",
    "W0 = np.eye(2)\n",
    "W1_1 = np.eye(2)\n",
    "W1_2 = np.zeros([2, 2])\n",
    "W1 = np.vstack([W1_1, W1_2])\n",
    "W2 = np.full([1, 4], 1)\n",
    "# Initialization of X, H, B and Yhat\n",
    "H0 = np.zeros([n, m])\n",
    "H1 = np.zeros([4, m])\n",
    "H2 = np.zeros([1, m])\n",
    "X1 = np.zeros([n, m])\n",
    "X2 = np.zeros([4, m])\n",
    "Yhat = np.zeros([1, m])\n",
    "B0 = np.ones([n, 1])\n",
    "B1 = np.ones([4, 1])\n",
    "B2 = np.ones([1, 1])\n",
    "\n",
    "# Loop\n",
    "for g in range(h):\n",
    "    # layer 0\n",
    "    G0 = np.dot(W0, X0) + b0 * B0\n",
    "    H0 = identity(G0)\n",
    "    # layer 1\n",
    "    X1 = H0\n",
    "    G1 = np.dot(W1, X1) + b1 * B1\n",
    "    H1 = relu(G1)\n",
    "    # layer 2\n",
    "    X2 = H1\n",
    "    G2 = np.dot(W2, X2) + b2 * B2\n",
    "    H2 = activation(G2)\n",
    "    # Cost function\n",
    "    Yhat = H2\n",
    "    J[0, g] = (-1 / m) * np.sum((Y * np.log(Yhat)) + (1 - Y) * np.log(1 - Yhat))\n",
    "    # Update W2\n",
    "    dGdW2 = Y - Yhat\n",
    "    dJdb2 = (-1 / m) * np.sum(dGdW2)\n",
    "    dJdW2 = (-1 / m) * np.dot(dGdW2, X2.T)\n",
    "    b2 = b2 - alpha * dJdb2\n",
    "    W2 = W2 - alpha * dJdW2\n",
    "    # Update W1\n",
    "    dGdW1 = np.dot(W2.T, dGdW2) * d_relu(G1)\n",
    "    dJdb1 = (-1 / m) * np.sum(dGdW1)\n",
    "    dJdW1 = (-1 / m) * np.dot(dGdW1, X1.T)\n",
    "    b1 = b1 - alpha * dJdb1\n",
    "    W1 = W1 - alpha * dJdW1\n",
    "    # Record cost function\n",
    "    if g % 100 == 0:\n",
    "        cost_sample.append(J[0, g])\n",
    "    cost.append(J[0, g])\n",
    "        \n",
    "    for i in range(m):\n",
    "        if Yhat[0, i] > 0.5:\n",
    "            Yhat[0, i] = 1\n",
    "        else:\n",
    "            Yhat[0, i] = 0\n",
    "        \n",
    "print(\"b2 = {}\".format(b2))\n",
    "print(\"W2 = \", W2)\n",
    "print(\"b1 = {}\".format(b1))\n",
    "print(\"W1 = \", W1)\n",
    "print(\"Cost sample = {}\".format(cost_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Train set is 0.603125\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(m):\n",
    "    if Yhat[0, i] == Y_train[0, i]:\n",
    "        a += 1\n",
    "print(\"The accuracy of Train set is {}\".format(a / m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21360a88080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "plt.plot(cost)\n",
    "plt.legend(bbox_to_anchor=(1.0, 1), loc=1, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jcost = 0.6983269611813547\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "X0 = X_test\n",
    "Y = Y_test\n",
    "# Initialization\n",
    "n = 2\n",
    "m = X0.shape[1]\n",
    "G0 = np.zeros([n, m])\n",
    "G1 = np.zeros([4, m])\n",
    "G2 = np.zeros([1, m])\n",
    "dGdW1 = np.zeros([1, m])\n",
    "dJdW1 = np.zeros([1, n])\n",
    "dJdb1 = 0\n",
    "dGdW2 = np.zeros([1, m])\n",
    "dJdW2 = np.zeros([1, n])\n",
    "dJdb2 = 0\n",
    "# Model Parameters\n",
    "b0 = 0\n",
    "b1 = 0\n",
    "b2 = 1\n",
    "W0 = np.eye(2)\n",
    "W1_1 = np.eye(2)\n",
    "W1_2 = np.zeros([2, 2])\n",
    "W1 = np.vstack([W1_1, W1_2])\n",
    "W2 = np.full([1, 4], 1)\n",
    "# Initialization of X, H, B and Yhat\n",
    "H0 = np.zeros([n, m])\n",
    "H1 = np.zeros([4, m])\n",
    "H2 = np.zeros([1, m])\n",
    "X1 = np.zeros([n, m])\n",
    "X2 = np.zeros([4, m])\n",
    "Yhat = np.zeros([1, m])\n",
    "B0 = np.ones([n, 1])\n",
    "B1 = np.ones([4, 1])\n",
    "B2 = np.ones([1, 1])\n",
    "\n",
    "# Loop\n",
    "for g in range(h):\n",
    "    # layer 0\n",
    "    G0 = np.dot(W0, X0) + b0 * B0\n",
    "    H0 = identity(G0)\n",
    "    # layer 1\n",
    "    X1 = H0\n",
    "    G1 = np.dot(W1, X1) + b1 * B1\n",
    "    H1 = relu(G1)\n",
    "    # layer 2\n",
    "    X2 = H1\n",
    "    G2 = np.dot(W2, X2) + b2 * B2\n",
    "    H2 = activation(G2)\n",
    "    # Cost function\n",
    "    Yhat = H2\n",
    "    J[0, g] = (-1 / m) * np.sum((Y * np.log(Yhat)) + (1 - Y) * np.log(1 - Yhat))\n",
    "    # Update W2\n",
    "    dGdW2 = Y - Yhat\n",
    "    dJdb2 = (-1 / m) * np.sum(dGdW2)\n",
    "    dJdW2 = (-1 / m) * np.dot(dGdW2, X2.T)\n",
    "    b2 = -0.19474271702955998\n",
    "    W2 = np.array([[0.46481367, 0.59191156, 1.00000419, 1.00000419]])\n",
    "    # Update W1\n",
    "    dGdW1 = np.dot(W2.T, dGdW2) * d_relu(G1)\n",
    "    dJdb1 = (-1 / m) * np.sum(dGdW1)\n",
    "    dJdW1 = (-1 / m) * np.dot(dGdW1, X1.T)\n",
    "    b1 = -0.34422516710405987\n",
    "    W1 = np.array([[0.62759178, -0.23824469], [-0.15219613, 0.09509001], [-0.00290131, -0.01961629], [-0.00290131, -0.01961629]])\n",
    "        \n",
    "    for i in range(m):\n",
    "        if Yhat[0, i] > 0.5:\n",
    "            Yhat[0, i] = 1\n",
    "        else:\n",
    "            Yhat[0, i] = 0\n",
    "        \n",
    "print(\"Jcost = {}\".format(J[0, h-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Test set is 0.55\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(m):\n",
    "    if Yhat[0, i] == Y_test[0, i]:\n",
    "        a += 1\n",
    "print(\"The accuracy of Test set is {}\".format(a / m))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
